{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df0048f-a169-4ea3-b802-0ef52f5d6b81",
   "metadata": {},
   "source": [
    "## ETL using SPARK for nested json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8d1d3-9411-4de7-a314-571ad13c75c6",
   "metadata": {},
   "source": [
    "### import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e1da50-5d6d-4326-862e-6840b5458a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a823a5-5509-4ea8-acdd-230066dc7c9a",
   "metadata": {},
   "source": [
    "### create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a5fc64-a343-4b10-ad96-4b8ea2e7c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('nestedJSON').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cc09ac-f6e8-4d74-a859-d8d987bc93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('employee_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915c5509-db21-484a-9d30-3c82c55c7e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- candidate: struct (nullable = true)\n",
      " |    |    |    |-- experience: string (nullable = true)\n",
      " |    |    |    |-- first_name: string (nullable = true)\n",
      " |    |    |    |-- last_name: string (nullable = true)\n",
      " |    |    |    |-- relocation: string (nullable = true)\n",
      " |    |    |    |-- skills: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- specialty: string (nullable = true)\n",
      " |    |    |    |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3622295-0dc1-415f-9cab-e1147fe8d2a7",
   "metadata": {},
   "source": [
    "### explode features column and deal with candidate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e0b9ceb-cd92-4183-8485-f1c06904b1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           candidate|\n",
      "+--------------------+\n",
      "|{Mid, Margaret, M...|\n",
      "|{Senior, Michael,...|\n",
      "|{Mid, Brenda, Tyl...|\n",
      "|{Senior, Joseph, ...|\n",
      "|{Junior, Laura, W...|\n",
      "|{Mid, Cheryl, Ram...|\n",
      "|{Mid, Charles, St...|\n",
      "|{Senior, Bradley,...|\n",
      "|{Mid, William, Li...|\n",
      "|{Senior, Richard,...|\n",
      "|{Junior, Robert, ...|\n",
      "|{Mid, Tanya, Schu...|\n",
      "|{Senior, Scott, N...|\n",
      "|{Junior, Brett, H...|\n",
      "|{Junior, Sean, Wi...|\n",
      "|{Senior, Steven, ...|\n",
      "|{Mid, Mr., James,...|\n",
      "|{Junior, Linda, G...|\n",
      "|{Junior, Jacob, E...|\n",
      "|{Mid, Nicole, Mar...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat = df.select(explode('features').alias('Elements'))\n",
    "df_flat = df_flat.select('Elements.candidate')\n",
    "\n",
    "df_flat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd968732-f189-49ac-a1b2-022679bd4950",
   "metadata": {},
   "source": [
    "### the current format isn't quite what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8202e5d-cbbe-46cf-a0c8-884e735177fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- candidate: struct (nullable = true)\n",
      " |    |-- experience: string (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |    |-- relocation: string (nullable = true)\n",
      " |    |-- skills: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- specialty: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f22a5dc3-4ec8-4215-ae3f-a02b9d1d07e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+----------+------------------+--------------------+-----+\n",
      "|first_name|last_name|experience|relocation|         specialty|              skills|state|\n",
      "+----------+---------+----------+----------+------------------+--------------------+-----+\n",
      "|  Margaret| Mcdonald|       Mid|        no|          Database|[skLearn, Java, R...|   AL|\n",
      "|   Michael|   Carter|    Senior|       yes|        Statistics|[TensorFlow, R, S...|   AR|\n",
      "|    Brenda|    Tyler|       Mid|        no|          Database|             [Spark]|   UT|\n",
      "|    Joseph|     King|    Senior|     maybe|  Machine Learning|[skLearn, SQL, R,...|   FL|\n",
      "|     Laura|     Webb|    Junior|     maybe|  Machine Learning|[TensorFlow, C++,...|   WY|\n",
      "|    Cheryl|  Ramirez|       Mid|        no|Data Visualization|[C++, Python, R, ...|   OK|\n",
      "|   Charles|  Stewart|       Mid|     maybe|  Machine Learning|[MongoDB, C++, Ja...|   NM|\n",
      "|   Bradley| Peterson|    Senior|       yes|Data Visualization|[skLearn, MongoDB...|   TX|\n",
      "|   William|      Lin|       Mid|     maybe|  Machine Learning|[Python, skLearn, R]|   WI|\n",
      "|   Richard|    Woods|    Senior|       yes|          Database|  [skLearn, MongoDB]|   UT|\n",
      "|    Robert|   Rivera|    Junior|       yes|          Database|[Java, skLearn, P...|   PA|\n",
      "|     Tanya|  Schultz|       Mid|       yes|        Statistics|[SQL, MongoDB, R,...|   NV|\n",
      "|     Scott|    Nunez|    Senior|     maybe|          Database|[skLearn, Java, S...|   MO|\n",
      "|     Brett|  Hoffman|    Junior|        no|          Database|[Java, TensorFlow...|   OK|\n",
      "|      Sean| Williams|    Junior|        no|Data Visualization|[SQL, MongoDB, R,...|   NV|\n",
      "|    Steven|    Craig|    Senior|     maybe|Data Visualization|   [TensorFlow, SQL]|   ID|\n",
      "|       Mr.|    James|       Mid|     maybe|Data Visualization|[TensorFlow, Java...|   KY|\n",
      "|     Linda|  Griffin|    Junior|        no|        Statistics|[TensorFlow, Spar...|   NE|\n",
      "|     Jacob| Espinoza|    Junior|     maybe|        Statistics|           [skLearn]|   WV|\n",
      "|    Nicole|   Martin|       Mid|     maybe|Data Visualization|         [Java, SQL]|   NC|\n",
      "+----------+---------+----------+----------+------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat1=df.select(explode('features.candidate').alias('candi'))\n",
    "df_flat1 = df_flat1.select('candi.first_name','candi.last_name','candi.experience','candi.relocation','candi.specialty','candi.skills','candi.state')\n",
    "df_flat1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78ca19-1468-4890-9a39-0df753cc9238",
   "metadata": {},
   "source": [
    "### we have reached to the final format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ffb1b0-42a3-4044-897e-a9abadcee7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      " |-- relocation: string (nullable = true)\n",
      " |-- specialty: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e254839-08fe-43b6-848a-f1d78d6c9d46",
   "metadata": {},
   "source": [
    "### downlaod dataset to be a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59117be5-db70-4f71-91a1-78da4a027901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Unset HADOOP_HOME environment variable\n",
    "os.environ.pop('HADOOP_HOME', None)\n",
    "\n",
    "# Save DataFrame as CSV using Pandas\n",
    "df_flat1.toPandas().to_csv('employee_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394c76c-70e4-457b-ad55-796011063407",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## upload data into postgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "641e1dbb-40db-49e7-b9f8-eea7e55053db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07b8e2-1fd9-4385-9121-49979bbc9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"postgres\",\n",
    "            user=\"postgres\",\n",
    "            password=\"root\",\n",
    "            host=\"127.0.0.1\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53252e-8ba4-454b-bcbc-395e2a10d810",
   "metadata": {},
   "source": [
    "### Function to create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1300d43-f346-4db8-a5a9-fb1e75ba5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(conn):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS employee_data (\n",
    "                first_name TEXT,\n",
    "                last_name TEXT,\n",
    "                skills TEXT[],\n",
    "                state TEXT,\n",
    "                specialty TEXT,\n",
    "                experience TEXT,\n",
    "                relocation TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Error creating table.\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4bec1-ce59-4971-bef5-a8e91002288a",
   "metadata": {},
   "source": [
    "### Function to insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace8574-9855-4b57-b2da-10eda16d2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(conn, data):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # Format skills as an array\n",
    "        skills_arr = \"{\" + \", \".join([\"'{}'\".format(skill) for skill in data[2]]) + \"}\"\n",
    "        # Insert data into the table\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO employee_data (\n",
    "                first_name,\n",
    "                last_name,\n",
    "                skills,\n",
    "                state,\n",
    "                specialty,\n",
    "                experience,\n",
    "                relocation\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "        \"\"\", (data[0], data[1], skills_arr, data[3], data[4], data[5], data[6]))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Error inserting data.\")\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c8534-2223-46a6-8a19-f26cbb0607c5",
   "metadata": {},
   "source": [
    "### main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b460f0e-a9af-47d0-9bfd-34304bc48ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    conn = connect()\n",
    "    if conn is None:\n",
    "        return\n",
    "    create_table(conn)\n",
    "    for index, row in df.iterrows():\n",
    "        data = (row['first_name'], row['Last_Name'], row['skills'], row['state'], row['specialty'], row['experience'], row['relocation'])\n",
    "        insert_data(conn, data)\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
